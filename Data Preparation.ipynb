{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b4b30ee",
   "metadata": {},
   "source": [
    "# Using TPOT to Identify the Best Model for VOC Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe5c92e",
   "metadata": {},
   "source": [
    "## Importing Relevant Packages and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54989883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laram\\AppData\\Local\\Continuum\\anaconda3\\envs\\ca4015\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9ee7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('data/raw_data.xlsx', sheet_name=\"Wide\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6889721",
   "metadata": {},
   "source": [
    "## Restructuring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8feca8c",
   "metadata": {},
   "source": [
    "The data contains null values for columns, and the real column names are contained within a row in the dataframe.\n",
    "The row of column names need to be extracted, and added as the column names for the remaining data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c2ac633",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = data.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e87a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_content = data.iloc[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c525aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_content.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3982a264",
   "metadata": {},
   "source": [
    "# Creating test and train features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f361b701",
   "metadata": {},
   "source": [
    "The target label is the strain, and the features used to train the model exclude the strain, the species and the sample.\n",
    "The species and the sample are removed from the training features due to their link to the strain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64f64590",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_content.iloc[:,3:]\n",
    "targets = data_content.iloc[:,:3]\n",
    "strain_targets = targets.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b55707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features = features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b70deb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking that all columns are numeric\n",
    "features.shape[1] == features.select_dtypes(include=np.number).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4446674",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(features.shape)\n",
    "print(strain_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00189eb",
   "metadata": {},
   "source": [
    "## Normalising the feature vectors (if all were numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a804089",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a10482",
   "metadata": {},
   "outputs": [],
   "source": [
    "## mean normalised \n",
    "normalized_features=(features-features.mean())/features.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd84e102",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4b0d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_normalized_features=(features-features.min())/(features.max()-features.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5b5d2",
   "metadata": {},
   "source": [
    "## Normalizing the feature vectors (nulls still included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb5a784",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd729767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laram\\AppData\\Local\\Temp/ipykernel_13488/2199773025.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features[column]=(features[column]-features[column].min())/(features[column].max()-features[column].min())\n"
     ]
    }
   ],
   "source": [
    "for column in features.columns:\n",
    "    features[column]=(features[column]-features[column].min())/(features[column].max()-features[column].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a817659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>2</th>\n",
       "      <th>Ethyl Acetate</th>\n",
       "      <th>Ethanol</th>\n",
       "      <th>Propanoic acid, ethyl ester</th>\n",
       "      <th>2-Pentanone</th>\n",
       "      <th>Decane</th>\n",
       "      <th>Methyl Isobutyl Ketone</th>\n",
       "      <th>Amylene hydrate</th>\n",
       "      <th>Butanoic acid, 2-methyl-, methyl ester</th>\n",
       "      <th>Isobutyl acetate</th>\n",
       "      <th>Methyl isovalerate</th>\n",
       "      <th>...</th>\n",
       "      <th>1-Dodecanol</th>\n",
       "      <th>Methyl tetradecanoate</th>\n",
       "      <th>2-Pentadecanone</th>\n",
       "      <th>Tetradecanoic acid, ethyl ester</th>\n",
       "      <th>Hexadecanal</th>\n",
       "      <th>n-Tridecan-1-ol</th>\n",
       "      <th>1-Tetradecanol</th>\n",
       "      <th>n-Pentadecanol</th>\n",
       "      <th>1-Hexadecanol</th>\n",
       "      <th>Indole</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3484</td>\n",
       "      <td>0.095694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.280738</td>\n",
       "      <td>0.267534</td>\n",
       "      <td>0.247824</td>\n",
       "      <td>0.096187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.144602</td>\n",
       "      <td>0.09786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.109738</td>\n",
       "      <td>0.098475</td>\n",
       "      <td>0.144856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.301918</td>\n",
       "      <td>0.172296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.254583</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.174291</td>\n",
       "      <td>0.096902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.097199</td>\n",
       "      <td>0.478675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.419277</td>\n",
       "      <td>0.041532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.08767</td>\n",
       "      <td>0.318686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.089323</td>\n",
       "      <td>0.127058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.096124</td>\n",
       "      <td>0.13512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.952934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.231334</td>\n",
       "      <td>0.526166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.603602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.410589</td>\n",
       "      <td>0.334106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.254093</td>\n",
       "      <td>0.369002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.650532</td>\n",
       "      <td>0.116344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.914574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.259225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112936</td>\n",
       "      <td>0.848228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "2   Ethyl Acetate   Ethanol Propanoic acid, ethyl ester 2-Pentanone    Decane  \\\n",
       "3          0.3484  0.095694                         NaN    0.280738  0.267534   \n",
       "4        0.144602   0.09786                         NaN    0.109738  0.098475   \n",
       "5        0.301918  0.172296                         NaN    0.254583  0.000005   \n",
       "6        0.097199  0.478675                         NaN    0.419277  0.041532   \n",
       "7         0.08767  0.318686                         NaN    0.053714       0.0   \n",
       "..            ...       ...                         ...         ...       ...   \n",
       "82       0.089323  0.127058                         0.0    0.036897       0.0   \n",
       "83       0.096124   0.13512                         0.0    0.078258       0.0   \n",
       "84       0.231334  0.526166                         0.0    0.190671       0.0   \n",
       "85       0.410589  0.334106                         0.0    0.138788       0.0   \n",
       "86       0.254093  0.369002                         0.0    0.650532  0.116344   \n",
       "\n",
       "2  Methyl Isobutyl Ketone Amylene hydrate  \\\n",
       "3                0.247824        0.096187   \n",
       "4                0.144856             0.0   \n",
       "5                0.174291        0.096902   \n",
       "6                     0.0        0.248146   \n",
       "7                     0.0             0.0   \n",
       "..                    ...             ...   \n",
       "82                    NaN             0.0   \n",
       "83                    NaN             0.0   \n",
       "84                    NaN        0.143815   \n",
       "85                    NaN         0.08014   \n",
       "86                    NaN        0.914574   \n",
       "\n",
       "2  Butanoic acid, 2-methyl-, methyl ester Isobutyl acetate Methyl isovalerate  \\\n",
       "3                                     NaN              NaN                0.0   \n",
       "4                                     NaN              NaN                0.0   \n",
       "5                                     NaN              NaN                0.0   \n",
       "6                                     NaN              NaN                0.0   \n",
       "7                                     NaN              NaN                0.0   \n",
       "..                                    ...              ...                ...   \n",
       "82                                    NaN              0.0                NaN   \n",
       "83                                    NaN              0.0                NaN   \n",
       "84                                    NaN              0.0                NaN   \n",
       "85                                    NaN              0.0                NaN   \n",
       "86                                    NaN              0.0                NaN   \n",
       "\n",
       "2   ... 1-Dodecanol Methyl tetradecanoate  2-Pentadecanone  \\\n",
       "3   ...         NaN                   NaN              NaN   \n",
       "4   ...         NaN                   NaN              NaN   \n",
       "5   ...         NaN                   NaN              NaN   \n",
       "6   ...         NaN                   NaN              NaN   \n",
       "7   ...         NaN                   NaN              NaN   \n",
       "..  ...         ...                   ...              ...   \n",
       "82  ...    0.005973                   0.0              0.0   \n",
       "83  ...    0.064019                   0.0              0.0   \n",
       "84  ...    0.029894                   0.0              0.0   \n",
       "85  ...    0.316324                   0.0              0.0   \n",
       "86  ...         1.0                   1.0              1.0   \n",
       "\n",
       "2  Tetradecanoic acid, ethyl ester Hexadecanal n-Tridecan-1-ol 1-Tetradecanol  \\\n",
       "3                              NaN         NaN             NaN            NaN   \n",
       "4                              NaN         NaN             NaN            NaN   \n",
       "5                              NaN         NaN             NaN            NaN   \n",
       "6                              NaN         NaN             NaN            NaN   \n",
       "7                              NaN         NaN             NaN            NaN   \n",
       "..                             ...         ...             ...            ...   \n",
       "82                             0.0         0.0             0.0            0.0   \n",
       "83                             0.0         0.0             0.0       0.032103   \n",
       "84                             0.0         0.0             0.0       0.034451   \n",
       "85                             0.0         0.0             0.0        0.05972   \n",
       "86                             0.0         0.0             0.0       0.259225   \n",
       "\n",
       "2  n-Pentadecanol  1-Hexadecanol    Indole  \n",
       "3             NaN            NaN       NaN  \n",
       "4             NaN            NaN       NaN  \n",
       "5             NaN            NaN       NaN  \n",
       "6             NaN            NaN       NaN  \n",
       "7             NaN            NaN       NaN  \n",
       "..            ...            ...       ...  \n",
       "82            0.0            0.0  0.488614  \n",
       "83            0.0            0.0  0.952934  \n",
       "84            0.0            0.0  0.603602  \n",
       "85            0.0            0.0  0.732048  \n",
       "86            0.0       0.112936  0.848228  \n",
       "\n",
       "[84 rows x 67 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73548cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42cf6d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## checking that all columns are numeric\n",
    "features.shape[1] == features.select_dtypes(include=np.number).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85a15f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c412a839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8da9e1d1",
   "metadata": {},
   "source": [
    "## Converting target data to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a706c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_array = np.array(strain_targets).reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e5bab",
   "metadata": {},
   "source": [
    "## Adjusting the target values to be integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de1cbb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_integer_conversion = {\n",
    "    'SA_A' : 1,\n",
    "    'SA_B' : 2,\n",
    "    'PA_A' : 3,\n",
    "    'PA_B' : 4,\n",
    "    'EC_A' : 5,\n",
    "    'EC_B' : 6\n",
    "}\n",
    "\n",
    "for target in range(0,len(targets_array)):\n",
    "    if targets_array[target] in strain_integer_conversion.keys():\n",
    "        targets_array[target] = strain_integer_conversion[targets_array[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702fa7b5",
   "metadata": {},
   "source": [
    "## Using TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7387a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def my_custom_accuracy(y_true, y_pred):\n",
    "    return float(sum(y_pred == y_true)) / len(y_true)\n",
    "\n",
    "my_custom_scorer = make_scorer(my_custom_accuracy, greater_is_better=True)\n",
    "\n",
    "# Create a tpot object with a few parameters\n",
    "tpot = TPOTClassifier(scoring = my_custom_scorer, \n",
    "                    max_time_mins = 60, \n",
    "                    n_jobs = -1,\n",
    "                    verbosity = 2,\n",
    "                    cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9827d90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43ece4bc1ed4e90820299fe8bd77b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.5573529411764706\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.5573529411764706\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.5573529411764706\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.5595588235294118\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.5705882352941176\n",
      "\n",
      "Generation 6 - Current best internal CV score: 0.5823529411764706\n",
      "\n",
      "Generation 7 - Current best internal CV score: 0.5823529411764706\n",
      "\n",
      "Generation 8 - Current best internal CV score: 0.5941176470588235\n",
      "\n",
      "Generation 9 - Current best internal CV score: 0.5941176470588235\n",
      "\n",
      "Generation 10 - Current best internal CV score: 0.6051470588235295\n",
      "\n",
      "Generation 11 - Current best internal CV score: 0.6051470588235295\n",
      "\n",
      "Generation 12 - Current best internal CV score: 0.6080882352941177\n",
      "\n",
      "Generation 13 - Current best internal CV score: 0.6316176470588235\n",
      "\n",
      "Generation 14 - Current best internal CV score: 0.6316176470588235\n",
      "\n",
      "Generation 15 - Current best internal CV score: 0.6316176470588235\n",
      "\n",
      "Generation 16 - Current best internal CV score: 0.6316176470588235\n",
      "\n",
      "Generation 17 - Current best internal CV score: 0.6316176470588235\n",
      "\n",
      "Generation 18 - Current best internal CV score: 0.6316176470588235\n",
      "\n",
      "Generation 19 - Current best internal CV score: 0.6316176470588235\n",
      "\n",
      "Generation 20 - Current best internal CV score: 0.6316176470588235\n",
      "\n",
      "Generation 21 - Current best internal CV score: 0.6316176470588235\n",
      "\n",
      "Generation 22 - Current best internal CV score: 0.6316176470588235\n",
      "\n",
      "Generation 23 - Current best internal CV score: 0.6316176470588235\n",
      "\n",
      "Generation 24 - Current best internal CV score: 0.6316176470588235\n",
      "\n",
      "Generation 25 - Current best internal CV score: 0.6316176470588235\n",
      "\n",
      "Generation 26 - Current best internal CV score: 0.6316176470588235\n",
      "\n",
      "Generation 27 - Current best internal CV score: 0.6316176470588235\n",
      "\n",
      "Generation 28 - Current best internal CV score: 0.6316176470588235\n",
      "\n",
      "Generation 29 - Current best internal CV score: 0.6316176470588235\n",
      "\n",
      "60.11 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: XGBClassifier(Normalizer(PolynomialFeatures(input_matrix, degree=2, include_bias=False, interaction_only=False), norm=l1), learning_rate=1.0, max_depth=4, min_child_weight=1, n_estimators=100, n_jobs=1, subsample=0.9500000000000001, verbosity=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(max_time_mins=60, n_jobs=-1,\n",
       "               scoring=make_scorer(my_custom_accuracy), verbosity=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the tpot model on the training data\n",
    "tpot.fit(features, targets_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad01ec16",
   "metadata": {},
   "source": [
    "### Best algorithm using min-max-normalised features (excluding nulls) after 60 mins\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303c2393",
   "metadata": {},
   "source": [
    "### Best Algorithm using min-max-normalised features after 60 mins\n",
    "\n",
    "Generation 56 - Current best internal CV score: 0.7286764705882353\n",
    "\n",
    "60.11 minutes have elapsed. TPOT will close down.\n",
    "TPOT closed during evaluation in one generation.\n",
    "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
    "\n",
    "\n",
    "TPOT closed prematurely. Will use the current best pipeline.\n",
    "\n",
    "Best pipeline: XGBClassifier(Binarizer(XGBClassifier(SelectFwe(Normalizer(input_matrix, norm=l2), alpha=0.018000000000000002), learning_rate=1.0, max_depth=10, min_child_weight=1, n_estimators=100, n_jobs=1, subsample=0.7500000000000001, verbosity=0), threshold=0.65), learning_rate=0.1, max_depth=3, min_child_weight=1, n_estimators=100, n_jobs=1, subsample=0.9000000000000001, verbosity=0)\n",
    "TPOTClassifier(max_time_mins=60, n_jobs=-1,\n",
    "               scoring=make_scorer(my_custom_accuracy), verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06926b13",
   "metadata": {},
   "source": [
    "### Best algorithm using min-max-normalised features after 5 minutes\n",
    "\n",
    "Generation 6 - Current best internal CV score: 0.6051470588235295\n",
    "\n",
    "5.01 minutes have elapsed. TPOT will close down.\n",
    "TPOT closed during evaluation in one generation.\n",
    "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
    "\n",
    "\n",
    "TPOT closed prematurely. Will use the current best pipeline.\n",
    "\n",
    "Best pipeline: XGBClassifier(MinMaxScaler(VarianceThreshold(input_matrix, threshold=0.05)), learning_rate=0.5, max_depth=8, min_child_weight=4, n_estimators=100, n_jobs=1, subsample=0.8500000000000001, verbosity=0)\n",
    "TPOTClassifier(max_time_mins=5, n_jobs=-1,\n",
    "               scoring=make_scorer(my_custom_accuracy), verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b7c8d",
   "metadata": {},
   "source": [
    "### Best algorithm using mean-normalised features\n",
    "\n",
    "Generation 6 - Current best internal CV score: 0.5823529411764705\n",
    "\n",
    "5.24 minutes have elapsed. TPOT will close down.\n",
    "TPOT closed during evaluation in one generation.\n",
    "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
    "\n",
    "\n",
    "TPOT closed prematurely. Will use the current best pipeline.\n",
    "\n",
    "Best pipeline: XGBClassifier(input_matrix, learning_rate=0.5, max_depth=8, min_child_weight=1, n_estimators=100, n_jobs=1, subsample=0.9000000000000001, verbosity=0)\n",
    "TPOTClassifier(max_time_mins=5, n_jobs=-1,\n",
    "               scoring=make_scorer(my_custom_accuracy), verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bfa313",
   "metadata": {},
   "source": [
    "### Best algorithm after using entire dataset to train (un-normalised)\n",
    "\n",
    "Generation 89 - Current best internal CV score: 0.7139705882352941\n",
    "\n",
    "240.33 minutes have elapsed. TPOT will close down.\n",
    "TPOT closed during evaluation in one generation.\n",
    "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
    "\n",
    "\n",
    "TPOT closed prematurely. Will use the current best pipeline.\n",
    "\n",
    "Best pipeline: XGBClassifier(VarianceThreshold(Normalizer(input_matrix, norm=max), threshold=0.0005), learning_rate=0.1, max_depth=4, min_child_weight=1, n_estimators=100, n_jobs=1, subsample=0.9500000000000001, verbosity=0)\n",
    "TPOTClassifier(max_time_mins=240, n_jobs=-1,\n",
    "               scoring=make_scorer(my_custom_accuracy), verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbd72dd",
   "metadata": {},
   "source": [
    "### Best algorithm based on accuracy and running for 4 hours\n",
    "\n",
    "Generation 100 - Current best internal CV score: 0.8030303030303031\n",
    "\n",
    "Best pipeline: XGBClassifier(SelectPercentile(Normalizer(input_matrix, norm=max), percentile=44), learning_rate=0.1, max_depth=7, min_child_weight=1, n_estimators=100, n_jobs=1, subsample=0.6000000000000001, verbosity=0)\n",
    "TPOTClassifier(max_time_mins=240, n_jobs=-1,\n",
    "               scoring=make_scorer(my_custom_accuracy), verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c8454",
   "metadata": {},
   "source": [
    "### Output of TPOT Classifier with Custom Scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ebd76c",
   "metadata": {},
   "source": [
    "Generation 14 - Current best internal CV score: 0.7666666666666667\n",
    "\n",
    "12.04 minutes have elapsed. TPOT will close down.\n",
    "TPOT closed during evaluation in one generation.\n",
    "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
    "\n",
    "\n",
    "TPOT closed prematurely. Will use the current best pipeline.\n",
    "\n",
    "Best pipeline: XGBClassifier(Normalizer(input_matrix, norm=l1), learning_rate=0.1, max_depth=5, min_child_weight=1, n_estimators=100, n_jobs=1, subsample=0.8500000000000001, verbosity=0)\n",
    "TPOTClassifier(max_time_mins=12, n_jobs=-1,\n",
    "               scoring=make_scorer(my_custom_accuracy), verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6fbefb",
   "metadata": {},
   "source": [
    "### Output of TPOT Classifier with Negative Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ba8fa9",
   "metadata": {},
   "source": [
    "Generation 90 - Current best internal CV score: -0.1787878787878788\n",
    "\n",
    "120.04 minutes have elapsed. TPOT will close down.\n",
    "TPOT closed during evaluation in one generation.\n",
    "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
    "\n",
    "\n",
    "TPOT closed prematurely. Will use the current best pipeline.\n",
    "\n",
    "Best pipeline: XGBClassifier(Normalizer(CombineDFs(input_matrix, RobustScaler(ZeroCount(Normalizer(input_matrix, norm=l1)))), norm=max), learning_rate=0.1, max_depth=1, min_child_weight=1, n_estimators=100, n_jobs=1, subsample=0.7000000000000001, verbosity=0)\n",
    "TPOTClassifier(max_time_mins=120, n_jobs=-1, scoring='neg_mean_absolute_error',\n",
    "               verbosity=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63298d64",
   "metadata": {},
   "source": [
    "### Exporting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1430e141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d7e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the final model\n",
    "print(tpot.fitted_pipeline_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d5399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the pipeline as a python script file\n",
    "tpot.export('tpot_exported_pipeline.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
